---
title: "Named entity recognition with skincare routines"
author: "Jamie Ralph"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```


In this markdown document I will be applying some named entity recognition (NER) to YouTube skincare routines. In short, NER use a statistical model to assign a label to an entity (for example: people, organisations, locations). Here I will be running NER with the spaCy package in Python with the small version of [their pre-trained English language pipeline](https://spacy.io/models/en). 

## Data pre-processing

I'll first load up the data and do some pre-processing in R:

```{r}
library(here)
library(tidyverse)
library(tidytext)
library(glue)
library(reticulate)

# Get vector of file names
person <- list.files(here("skincare_transcripts")) %>%
    str_remove_all(".txt") %>%
    str_replace_all("_", " ")

# Extract text as character vector
routine_text <- list.files(here("skincare_transcripts"), full.names = T) %>%
    map_chr(read_file) %>%
    str_replace_all("\\r", " ") %>%
    str_replace_all("\\n", " ") %>%
    str_replace_all("- ", "")

# Convert to a tibble for analysis
routine_df <- tibble(
    person = person,
    text = routine_text
)

# Remove sound effects (found inside brackets)
routine_df <- routine_df %>%
  mutate(
    text = str_remove_all(text, "\\s*\\([^\\)]+\\)")
  )
```

## Run NER with spaCy

Now it's time for the NER. First I'll import spaCy and import the model, then print the text data out:

```{python, warning = FALSE}
import spacy

spacy_model = spacy.load("en_core_web_sm")

df = r.routine_df

print(df.head())
```

Now I'll use a list comprehension to identify named entities for each transcript:

```{python}
text_list = df.text.tolist()

result = [spacy_model(text) for text in text_list]
```

I'd like to extract the named entities and their labels from the result objects. I'll define a function to extract each result as a dataframe, then concatenate them all together. 


```{python}
import pandas as pd

def extract_entities(labelled_text):
  
  term = []
  label = []
  
  for word in labelled_text.ents:
    term.append(word.text)
    label.append(word.label_)
    
  return pd.DataFrame({"term": term, "label": label})

skincare_ner = pd.concat([extract_entities(text) for text in result])


```
## Check results


Let's look at the results of the NER model:

```{python}
skincare_ner.value_counts("label", ascending = False)
```

The most popular category are CARDINAL, which are numerals not falling under another type, so we ignore these. Let's look at the most popular PERSON tags:

```{python}
df = skincare_ner[skincare_ner["label"] == "PERSON"].value_counts("term", ascending = False)

df.head(5)

```

So, we have a few mentions of Barbara Sturm, a luxury skincare brand. But we also have Unicorn Mist which certainly isn't a person! This could be a result of both words being capitalised (I'll blame Paris Hilton for that one).

Let's look at the PRODUCTS category:

```{python}
df = skincare_ner[skincare_ner["label"] == "PRODUCT"].value_counts("term", ascending = False)

df.head(5)

```

These make a little more sense. We have makeup remover wipes, tissues, chemical exfoliators (AHAs), and a moisturizer. 

Finally, let's look at the ORG label (includes companies, agencies etc.):

```{python}
df = skincare_ner[skincare_ner["label"] == "ORG"].value_counts("term", ascending = False)

df.head(5)

```

Some good results here, including skincare brands and CVS Pharmacy. 

## Conclusion

NER is an efficient technique for identifying named entities in a large body of text. The results here weren't perfect, but the model performed well considering that it was the small version of spaCy's models and was applied to YouTube transcripts, which can be messier than written text. 